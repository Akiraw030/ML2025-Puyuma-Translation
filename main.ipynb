{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11640807,"sourceType":"datasetVersion","datasetId":7304401}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:24:29.317049Z","iopub.execute_input":"2025-06-10T10:24:29.317245Z","iopub.status.idle":"2025-06-10T10:24:29.539198Z","shell.execute_reply.started":"2025-06-10T10:24:29.317218Z","shell.execute_reply":"2025-06-10T10:24:29.538291Z"}},"outputs":[{"name":"stdout","text":"Tue Jun 10 10:24:29 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   39C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   41C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Package download\n\n!pip install sentencepiece -q\n!pip install transformers -q\n!pip install datasets -q\n!pip install peft -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:24:29.541272Z","iopub.execute_input":"2025-06-10T10:24:29.541491Z","iopub.status.idle":"2025-06-10T10:26:02.070117Z","shell.execute_reply.started":"2025-06-10T10:24:29.541472Z","shell.execute_reply":"2025-06-10T10:26:02.069387Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Part1","metadata":{}},{"cell_type":"code","source":"# Nllb loading\n\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel_name = \"facebook/nllb-200-distilled-600M\"\n# model_name = \"facebook/nllb-200-3.3B\" # Larger model\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\ntokenizer.src_lang = \"zho_Hant\"\ntokenizer.tgt_lang = \"tgl_Latn\"\n# zho_Hant for Chinese traditional\n# eng_Latn for English\n# tgl_Latn for Puyuma (Use existing language tag)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:26:02.071057Z","iopub.execute_input":"2025-06-10T10:26:02.071304Z","iopub.status.idle":"2025-06-10T10:26:55.170035Z","shell.execute_reply.started":"2025-06-10T10:26:02.071283Z","shell.execute_reply":"2025-06-10T10:26:55.168398Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1e29919dc0645bb99e21d4ed91e9578"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(…)6cea38b9e3d5efcdcb9c251d6b40538e1aab555a:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0b273c3c57e432f8c22007576286337"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(…)b3c438311629547285129b0b81dadabd01bca665:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6abcf0e0a5e740038061f0be8106dca7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52cc43062dc44469b7f8b4ebbf931e61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c35029f2fafd4327999e0bd5d2456b38"}},"metadata":{}},{"name":"stderr","text":"2025-06-10 10:26:24.673960: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749551185.086143      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749551185.226357      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nXet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"(…)1ecdf1e485509035f6b51dfe84f1ada83eefcc42:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f86e993740194e35a30c38b6a92b8675"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91787446b4f2479197ac83391f6b65ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b9e61c220b14f479cc8305e5f2735a5"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Load data into dataframes\n\nimport pandas as pd\n\nlexicon = pd.read_csv('/kaggle/input/ml2025-bonus/dataset/lexicon_no_en.csv', sep=\",\", quotechar='\"', header=None, encoding=\"utf-8\")\nlexicon.columns = ['pyu', 'zho']\n\nlexicon_en = pd.read_csv('/kaggle/input/ml2025-bonus/dataset/lexicon.csv', sep=\",\", quotechar='\"', header=None, encoding=\"utf-8\")\nlexicon_en.columns = ['pyu', 'eng', 'zho']\n\nsentences = pd.read_csv('/kaggle/input/ml2025-bonus/dataset/sentences_no_en.csv', sep=\",\", quotechar='\"', header=None, encoding=\"utf-8\")\nsentences.columns = ['pyu', 'zho']\n\nsentences_en = pd.read_csv('/kaggle/input/ml2025-bonus/dataset/sentences.csv', sep=\",\", quotechar='\"', header=None, encoding=\"utf-8\")\nsentences_en.columns = ['pyu', 'eng', 'zho']\n\n#lexicon.sample(5)\n#lexicon_en.sample(10)\n#sentences.sample(5)\n#sentences_en.sample(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:26:55.171731Z","iopub.execute_input":"2025-06-10T10:26:55.172483Z","iopub.status.idle":"2025-06-10T10:26:55.256830Z","shell.execute_reply.started":"2025-06-10T10:26:55.172423Z","shell.execute_reply":"2025-06-10T10:26:55.255936Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Testing the performances of original tokenization\n\nimport re\n\ndef word_tokenize(text):\n    \n    return re.findall('(\\w+|[^\\w\\s])', text)\n\ndef df_tokenize(df):\n    df['pyu_toks'] = df.pyu.apply(tokenizer.tokenize)\n    df['zho_toks'] = df.zho.apply(tokenizer.tokenize)\n    df['pyu_words'] = df.pyu.apply(word_tokenize)\n    df['zho_words'] = df.zho.apply(word_tokenize)\n    \n    return df\n\ndef cal_tokperword(df):\n\n    stats = df[['pyu_toks', 'zho_toks', 'pyu_words', 'zho_words']].map(len).describe()\n    print(stats.pyu_toks['mean'] / stats.pyu_words['mean'])\n    print(stats.zho_toks['mean'] / stats.zho_words['mean'])\n\n    return stats\n\ndef check_unk(df, column):\n\n    texts_with_unk = [\n        text for text in df[column]\n        if tokenizer.unk_token_id in tokenizer(text).input_ids\n    ]\n    print(len(texts_with_unk))\n\nlexicon = df_tokenize(lexicon)\nlexicon_en = df_tokenize(lexicon_en)\nsentences = df_tokenize(sentences)\nsentences_en = df_tokenize(sentences_en)\n\nprint(\"toks per word of lexicon:\")\nstats_lexicon = cal_tokperword(lexicon)\nprint(\"toks per word of lexicon_en:\")\nstats_lexicon = cal_tokperword(lexicon_en)\nprint(\"toks per word of sentences:\")\nstats_sentences = cal_tokperword(sentences)\nprint(\"toks per word of sentences_en:\")\nstats_sentences = cal_tokperword(sentences_en)\n\nprint(\"total unk in lexicon zho:\")\ncheck_unk(lexicon, \"zho\")\nprint(\"total unk in lexicon pyu:\")\ncheck_unk(lexicon, \"pyu\")\nprint(\"total unk in lexicon_en zho:\")\ncheck_unk(lexicon_en, \"zho\")\nprint(\"total unk in lexicon_en pyu:\")\ncheck_unk(lexicon_en, \"pyu\")\nprint(\"total unk in sentences zho:\")\ncheck_unk(sentences, \"zho\")\nprint(\"total unk in sentences pyu:\")\ncheck_unk(sentences, \"pyu\")\nprint(\"total unk in sentences_en zho:\")\ncheck_unk(sentences_en, \"zho\")\nprint(\"total unk in sentences pyu:\")\ncheck_unk(sentences_en, \"pyu\")\n\n#show datas\n#lexicon.sample(10)\n#sentences.sample(10)\n#stats_lexicon\n#stats_sentences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:26:55.257744Z","iopub.execute_input":"2025-06-10T10:26:55.257951Z","iopub.status.idle":"2025-06-10T10:27:01.403001Z","shell.execute_reply.started":"2025-06-10T10:26:55.257934Z","shell.execute_reply":"2025-06-10T10:27:01.402029Z"}},"outputs":[{"name":"stdout","text":"toks per word of lexicon:\n2.2840203274985886\n2.3545659526493803\ntoks per word of lexicon_en:\n1.738603297769156\n2.2698515171078117\ntoks per word of sentences:\n1.5806060606060606\n3.925910765452312\ntoks per word of sentences_en:\n1.5050038491147038\n3.165337423312884\ntotal unk in lexicon zho:\n97\ntotal unk in lexicon pyu:\n0\ntotal unk in lexicon_en zho:\n203\ntotal unk in lexicon_en pyu:\n0\ntotal unk in sentences zho:\n223\ntotal unk in sentences pyu:\n36\ntotal unk in sentences_en zho:\n142\ntotal unk in sentences pyu:\n14\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Training tokenizer for missing tokens\n\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport re\nfrom collections import Counter\nimport sentencepiece as spm\nfrom datasets import load_dataset\n\nall_texts = lexicon['zho'].dropna().tolist() + sentences['zho'].dropna().tolist() + lexicon_en['zho'].dropna().tolist() + sentences_en['zho'].dropna().tolist() + lexicon['pyu'].dropna().tolist() + sentences['pyu'].dropna().tolist() + lexicon_en['pyu'].dropna().tolist() + sentences_en['pyu'].dropna().tolist()\n\nall_texts_file = 'all_texts_plain.txt'\nwith open(all_texts_file, 'w', encoding='utf-8') as f:\n    for text in all_texts:\n        print(text, file=f)\n\nrequired_chars = set()\n\nfor text in tqdm(all_texts):\n    for char in text:\n        tokens = tokenizer.tokenize(char)\n        if tokens == ['▁', '<unk>']:\n            required_chars.add(char)\n\nrequired_chars_str = \"\".join(sorted(list(required_chars)))\nprint(f\"需要強制包含的單字元: {required_chars_str}\")\n\nspm.SentencePieceTrainer.train(\n    input=all_texts_file,\n    model_prefix='spm_new',\n    vocab_size=5800,\n    character_coverage=1,\n    num_threads=16,\n    train_extremely_large_corpus=False,\n    add_dummy_prefix=False,\n    max_sentencepiece_length=128,\n    max_sentence_length=4192 * 4,\n    pad_id=0,\n    eos_id=1,\n    unk_id=2,\n    bos_id=-1,\n    required_chars=required_chars_str,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:27:01.404087Z","iopub.execute_input":"2025-06-10T10:27:01.404306Z","iopub.status.idle":"2025-06-10T10:27:10.499297Z","shell.execute_reply.started":"2025-06-10T10:27:01.404289Z","shell.execute_reply":"2025-06-10T10:27:10.498545Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8770 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fceb2731b0f4a018f767d45b08cff21"}},"metadata":{}},{"name":"stdout","text":"需要強制包含的單字元: ’“”仟傻儼兇兜冀凳刮剁剝劈勻厲叢叮吱吵吼咀咕咱哇哎唉唬唷啃啄啥喂喔嗚嗯嘻噁噎嚀嚏嚕嚥嚨嚼囉囑坍垮墮墾壑夾妝妳姑姨婿媳嫂嬸宋寞屁屎屹岔峨峭峽嶺嶼巍巒廚廨彎徊徘怔怡惱懶扁扛扯抖拂拇拌拚捻掀掐揉揍揹搓搔搗搥摺撐撥撩撬擠擲攀攜攤攪攬敞晃晉晾暈杓杵柑柚桐梳椒椽楊榔槌樑樸橘橡檜檳櫻殷氓氾汙洶涎涕淒湃湊湛溉溼滷漱漾漿潑澀澆澈澎濁濕濤瀉瀑灑灶炒烘烹煞煥熬燉燙燦燻爐犁猴琉瓢甕甩畝疊疤痠痰癢皂盈盪眶睏睜瞄瞌瞧瞰矚砌碩碴碾磚礱稻窩竄竊竿笆筌筍筷箏箕篩篳簍簷籃籬粥粿糠糬糯糰緻縷繡繩羌羸耆耍耙聆脖腋膛膿臀臼舀舅舔舖芋芙苣苧茅莓菇菸萵葵蓆蔔蔗蔥蕃蕉蕎蕗蕨薑薯藷蘿蚓蚤蚯蚱蛀蛙蜓蜢蜻蝦蝨蝴蝸螂螃螞蟑蟬蟹蟻蠅裙諧諱謠謾豎豹贛趴跛踢蹂蹦蹲躪辣迴逛遐邈邵鄒酗醃醬釀鈔鉤鋤鋸錘錶鍊鍬鎚鏟鏽鐮鐺鑰閒閩闆闡闢阱陡雉霜鞦韆颱颳飧餚餵饋駝驟髒鬍鬚鬧魄鳳鴨鴿鵝鹹鹽麴齒龜\n","output_type":"stream"},{"name":"stderr","text":"sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Add trained tokens to tokenizer and model\n\nfrom sentencepiece import sentencepiece_model_pb2 as sp_pb2_model\nfrom transformers import NllbTokenizer\n\nmodel_name = 'facebook/nllb-200-distilled-600M'\ntokenizer_nllb = NllbTokenizer.from_pretrained(model_name)\n\nsp_trained = spm.SentencePieceProcessor(model_file='spm_new.model')\nadded_spm = sp_pb2_model.ModelProto()\nadded_spm.ParseFromString(sp_trained.serialized_model_proto())\nold_spm_nllb = sp_pb2_model.ModelProto()\nold_spm_nllb.ParseFromString(tokenizer_nllb.sp_model.serialized_model_proto())\n\nnllb_tokens_set = {p.piece for p in old_spm_nllb.pieces}\nprev_min_score = old_spm_nllb.pieces[-1].score\nfor p in added_spm.pieces:\n    piece = p.piece\n    if p.type != 1:\n        continue\n    if piece not in nllb_tokens_set:\n        new_p = sp_pb2_model.ModelProto().SentencePiece()\n        new_p.piece = piece\n        new_p.score = p.score + prev_min_score\n        old_spm_nllb.pieces.append(new_p)\n\nNEW_SPM_NAME = 'spm_nllb_extended_268k.model'\nwith open(NEW_SPM_NAME, 'wb') as f:\n    f.write(old_spm_nllb.SerializeToString())\n\ntokenizer = NllbTokenizer.from_pretrained(model_name, vocab_file='spm_new.model')\nprint(len(tokenizer_nllb), len(tokenizer))\nadded_vocab = set(tokenizer.get_vocab()).difference(set(tokenizer_nllb.get_vocab()))\n#print(added_vocab)(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:27:10.501623Z","iopub.execute_input":"2025-06-10T10:27:10.502356Z","iopub.status.idle":"2025-06-10T10:27:17.038669Z","shell.execute_reply.started":"2025-06-10T10:27:10.502335Z","shell.execute_reply":"2025-06-10T10:27:17.037843Z"}},"outputs":[{"name":"stdout","text":"256204 6004\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## PART2","metadata":{}},{"cell_type":"code","source":"lexicon.sample(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:27:17.039531Z","iopub.execute_input":"2025-06-10T10:27:17.039848Z","iopub.status.idle":"2025-06-10T10:27:19.246641Z","shell.execute_reply.started":"2025-06-10T10:27:17.039816Z","shell.execute_reply":"2025-06-10T10:27:19.245960Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                pyu   zho                   pyu_toks         zho_toks  \\\n1267   pinu'utilran    裝有  [▁p, inu, ', uti, l, ran]        [▁, 裝, 有]   \n1002   ututratrawan  待人接物      [▁ut, ut, ratra, wan]  [▁, 待, 人, 接, 物]   \n923      kalre'ayan    方便        [▁kal, re, ', ayan]        [▁, 方, 便]   \n57            risem    鐵撬                 [▁ris, em]    [▁, 鐵, <unk>]   \n469   parepidapidan    多次   [▁par, ep, id, ap, idan]          [▁多, 次]   \n\n               pyu_words zho_words  \n1267  [pinu, ', utilran]      [裝有]  \n1002      [ututratrawan]    [待人接物]  \n923     [kalre, ', ayan]      [方便]  \n57               [risem]      [鐵撬]  \n469      [parepidapidan]      [多次]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pyu</th>\n      <th>zho</th>\n      <th>pyu_toks</th>\n      <th>zho_toks</th>\n      <th>pyu_words</th>\n      <th>zho_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1267</th>\n      <td>pinu'utilran</td>\n      <td>裝有</td>\n      <td>[▁p, inu, ', uti, l, ran]</td>\n      <td>[▁, 裝, 有]</td>\n      <td>[pinu, ', utilran]</td>\n      <td>[裝有]</td>\n    </tr>\n    <tr>\n      <th>1002</th>\n      <td>ututratrawan</td>\n      <td>待人接物</td>\n      <td>[▁ut, ut, ratra, wan]</td>\n      <td>[▁, 待, 人, 接, 物]</td>\n      <td>[ututratrawan]</td>\n      <td>[待人接物]</td>\n    </tr>\n    <tr>\n      <th>923</th>\n      <td>kalre'ayan</td>\n      <td>方便</td>\n      <td>[▁kal, re, ', ayan]</td>\n      <td>[▁, 方, 便]</td>\n      <td>[kalre, ', ayan]</td>\n      <td>[方便]</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>risem</td>\n      <td>鐵撬</td>\n      <td>[▁ris, em]</td>\n      <td>[▁, 鐵, &lt;unk&gt;]</td>\n      <td>[risem]</td>\n      <td>[鐵撬]</td>\n    </tr>\n    <tr>\n      <th>469</th>\n      <td>parepidapidan</td>\n      <td>多次</td>\n      <td>[▁par, ep, id, ap, idan]</td>\n      <td>[▁多, 次]</td>\n      <td>[parepidapidan]</td>\n      <td>[多次]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from transformers.optimization import Adafactor\nfrom transformers import get_constant_schedule_with_warmup\nmodel.cuda();\noptimizer = Adafactor(\n    [p for p in model.parameters() if p.requires_grad],\n    scale_parameter=False,\n    relative_step=False,\n    lr=1e-4,\n    clip_threshold=1.0,\n    weight_decay=1e-3,\n)\nscheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:27:19.247468Z","iopub.execute_input":"2025-06-10T10:27:19.247833Z","iopub.status.idle":"2025-06-10T10:27:20.408323Z","shell.execute_reply.started":"2025-06-10T10:27:19.247812Z","shell.execute_reply":"2025-06-10T10:27:20.407676Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import random\nLANGS = [('zho', 'zho_Hant'), ('pyu', 'tgl_Latn')]\n\ndfs = [lexicon, sentences, lexicon_en, sentences_en]\ndf_train = pd.concat([df[['pyu', 'zho']] for df in dfs], ignore_index=True)\n\ndef get_batch_pairs(batch_size, data=df_train):\n    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n    xx, yy = [], []\n    for _ in range(batch_size):\n        item = data.iloc[random.randint(0, len(data)-1)]\n        xx.append(item[l1])\n        yy.append(item[l2])\n    return xx, yy, long1, long2\n\n#print(get_batch_pairs(1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:27:20.409024Z","iopub.execute_input":"2025-06-10T10:27:20.409277Z","iopub.status.idle":"2025-06-10T10:27:20.417513Z","shell.execute_reply.started":"2025-06-10T10:27:20.409255Z","shell.execute_reply":"2025-06-10T10:27:20.416870Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"batch_size = 16  # 32 already doesn't fit well to 15GB of GPU memory\nmax_length = 128  # token sequences will be truncated\ntraining_steps = 50000  # Usually, I set a large number of steps,\n# and then just interrupt the training manually\nlosses = []  # with this list, I do very simple tracking of average loss\nMODEL_SAVE_PATH = '/kaggle/working/nllb_extended'  # on my Google drive","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:27:20.418220Z","iopub.execute_input":"2025-06-10T10:27:20.418437Z","iopub.status.idle":"2025-06-10T10:27:20.440811Z","shell.execute_reply.started":"2025-06-10T10:27:20.418413Z","shell.execute_reply":"2025-06-10T10:27:20.440287Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import gc\nimport torch\nimport numpy as np\nfrom tqdm.auto import tqdm, trange\n\ndef cleanup():\n    gc.collect()\n    torch.cuda.empty_cache()\n\nmodel.train()\nx, y, loss = None, None, None\ncleanup()\n\ntq = trange(len(losses), training_steps)\nfor i in tq:\n    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n    try:\n        tokenizer.src_lang = lang1\n        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n        tokenizer.src_lang = lang2\n        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n        # -100 is a magic value ignored in the loss function\n        # because we don't want the model to learn to predict padding ids\n        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n\n        loss = model(**x, labels=y.input_ids).loss\n        loss.backward()\n        losses.append(loss.item())\n\n        optimizer.step()\n        optimizer.zero_grad(set_to_none=True)\n        scheduler.step()\n\n    except RuntimeError as e:  # usually, it is out-of-memory\n        optimizer.zero_grad(set_to_none=True)\n        x, y, loss = None, None, None\n        cleanup()\n        print('error', max(len(s) for s in xx + yy), e)\n        continue\n\n    if i % 1000 == 0:\n        # each 1000 steps, I report average loss at these steps\n        print(i, np.mean(losses[-1000:]))\n\n    if i % 1000 == 0 and i > 0:\n        model.save_pretrained(MODEL_SAVE_PATH)\n        tokenizer.save_pretrained(MODEL_SAVE_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:27:20.441566Z","iopub.execute_input":"2025-06-10T10:27:20.441849Z","iopub.status.idle":"2025-06-10T10:41:38.324641Z","shell.execute_reply.started":"2025-06-10T10:27:20.441826Z","shell.execute_reply":"2025-06-10T10:41:38.323773Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f275f09653c942a5a3093c00af8e4991"}},"metadata":{}},{"name":"stdout","text":"0 10.844038009643555\n1000 6.1033971543312076\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## PART3","metadata":{}},{"cell_type":"code","source":"from transformers import NllbTokenizer, AutoModelForSeq2SeqLM\nmodel_load_name = '/kaggle/working/nllb_extended'\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_load_name).cuda()\ntokenizer = NllbTokenizer.from_pretrained(model_load_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:43:27.853166Z","iopub.execute_input":"2025-06-10T10:43:27.853451Z","iopub.status.idle":"2025-06-10T10:43:29.243533Z","shell.execute_reply.started":"2025-06-10T10:43:27.853433Z","shell.execute_reply":"2025-06-10T10:43:29.242985Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def translate(\n    text, src_lang='zho_Hant', tgt_lang='tgl_Latn', \n    a=32, b=3, max_input_length=1024, num_beams=1, **kwargs\n):\n    \"\"\"Turn a text or a list of texts into a list of translations\"\"\"\n    tokenizer.src_lang = src_lang\n    tokenizer.tgt_lang = tgt_lang\n    inputs = tokenizer(\n        text, return_tensors='pt', padding=True, truncation=True, \n        max_length=max_input_length\n    )\n    model.eval() # turn off training mode\n    result = model.generate(\n        **inputs.to(model.device),\n        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n        max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n        num_beams=num_beams, **kwargs\n    )\n    return tokenizer.batch_decode(result, skip_special_tokens=True)\n\nt = '今天是星期一'\nprint(translate(t, 'zho_Hant', 'tgl_Latn'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:48:51.138374Z","iopub.execute_input":"2025-06-10T10:48:51.138656Z","iopub.status.idle":"2025-06-10T10:48:51.308833Z","shell.execute_reply.started":"2025-06-10T10:48:51.138635Z","shell.execute_reply":"2025-06-10T10:48:51.308242Z"}},"outputs":[{"name":"stdout","text":"[\"'a'a'a'a'\"]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"sentences.sample(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:46:40.202784Z","iopub.execute_input":"2025-06-10T10:46:40.203065Z","iopub.status.idle":"2025-06-10T10:46:40.224197Z","shell.execute_reply.started":"2025-06-10T10:46:40.203045Z","shell.execute_reply":"2025-06-10T10:46:40.223599Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                                   pyu  \\\n264  nu uri paveray pakangaway za muketrep wariyan ...   \n22   na Pinuyumayan mu, 'azi kazuwan tu pinitrauwan...   \n862  2. puitrasaw lra na ayawan, arasaw lra na ayaw...   \n426  liyusan pukalruwatr wari? kiyumalra ku ziya ka...   \n330  kani i Pinuyumayan na Kasavakan zi na Katratri...   \n458                                 ulra lra mu alrak?   \n757  kinalrakan murairaip mu'uma, menadanadam mele'...   \n870  tu nana'uwan kana melrivak 'alrayan zantu ipar...   \n208  nu pararahan za ruma' pakangawayan za sa'ami p...   \n297  na pa'ira'iraw mu iniyam na zekalr i Pinuyumay...   \n\n                                                   zho  \\\n264                          在婚期前十天，男家邀集男性親屬一同搬送聘禮至女家。   \n22   卑南族人口雖不多，但卻很團結。卑南族有這麼優良的傳統文化，身為卑南族人，要好好珍惜，並擔任起...   \n862                   2.把頭目（領袖）抬上來了，把頭目（領袖）抬起來了，虛詞...…   \n426                                       週五嗎？我得問問其他人。   \n330      其中卑南族的建和與知本部落因往南遷徙時與昔日的排灣族已有血緣之故，木雕雷同的風格別具特色。   \n458                                           你們有孩子了嗎？   \n757                   從小結伴做農，學習編織及料理家務，也接受婦女道德傳統禮儀的訓練。   \n870                                  保障原住民族之平等地位及自主發展，   \n208  在蓋房子的前一年就要準備木柱及黃藤，尋找堅固實心不容易腐朽不會白蟻蛀掉的，三十、五十甚至一百...   \n297                所謂pa’ira’iraw的古謠是卑南族部落在年祭時男子所吟唱的歌謠。   \n\n                                              pyu_toks  \\\n264  [▁nu, ▁uri, ▁pa, ver, ay, ▁pakanga, way, ▁za, ...   \n22   [▁na, ▁P, inu, yum, ayan, ▁mu, ,, ▁', azi, ▁ka...   \n862  [▁2., ▁pu, itr, asaw, ▁l, ra, ▁na, ▁aya, wan, ...   \n426  [▁liy, usan, ▁puk, al, ru, wat, r, ▁wari, ?, ▁...   \n330  [▁kani, ▁i, ▁P, inu, yum, ayan, ▁na, ▁Kasa, v,...   \n458                [▁ul, ra, ▁l, ra, ▁mu, ▁al, rak, ?]   \n757  [▁kin, al, rakan, ▁mura, ira, ip, ▁mu, ', uma,...   \n870  [▁tu, ▁nana, ', uwan, ▁kana, ▁mel, ri, vak, ▁'...   \n208  [▁nu, ▁par, arahan, ▁za, ▁ruma, ', ▁pakanga, w...   \n297  [▁na, ▁pa, ', ira, ', ira, w, ▁mu, ▁ini, yam, ...   \n\n                                              zho_toks  \\\n264  [▁在, 婚, 期, 前, 十, 天, ,, 男, 家, 邀, 集, 男性, 親, 屬, 一...   \n22   [▁, 卑, 南, 族, 人口, 雖, 不, 多, ,, 但, 卻, 很, 團, 結, 。,...   \n862  [▁2., 把, 頭, 目, (, 領, 袖, ), 抬, 上, 來, 了, ,, 把, 頭...   \n426                [▁, 週, 五, 嗎, ?, 我, 得, 問, 問, 其他人, 。]   \n330  [▁其中, 卑, 南, 族, 的, 建, 和, 與, 知, 本, 部落, 因, 往, 南, ...   \n458                              [▁你們, 有, 孩子, 了, 嗎, ?]   \n757  [▁從, 小, 結, 伴, 做, 農, ,, 學習, 編, 織, 及, 料理, 家, 務, ...   \n870       [▁, 保障, 原, 住, 民族, 之, 平等, 地位, 及, 自, 主, 發展, ,]   \n208  [▁在, 蓋, 房, 子, 的, 前, 一年, 就要, 準備, 木, 柱, 及, 黃, 藤,...   \n297  [▁所, 謂, pa, <unk>, ira, <unk>, ira, w, 的, 古, <...   \n\n                                             pyu_words  \\\n264  [nu, uri, paveray, pakangaway, za, muketrep, w...   \n22   [na, Pinuyumayan, mu, ,, ', azi, kazuwan, tu, ...   \n862  [2, ., puitrasaw, lra, na, ayawan, ,, arasaw, ...   \n426  [liyusan, pukalruwatr, wari, ?, kiyumalra, ku,...   \n330  [kani, i, Pinuyumayan, na, Kasavakan, zi, na, ...   \n458                          [ulra, lra, mu, alrak, ?]   \n757  [kinalrakan, murairaip, mu, ', uma, ,, menadan...   \n870  [tu, nana, ', uwan, kana, melrivak, ', alrayan...   \n208  [nu, pararahan, za, ruma, ', pakangawayan, za,...   \n297  [na, pa, ', ira, ', iraw, mu, iniyam, na, zeka...   \n\n                                             zho_words  \n264                  [在婚期前十天, ，, 男家邀集男性親屬一同搬送聘禮至女家, 。]  \n22   [卑南族人口雖不多, ，, 但卻很團結, 。, 卑南族有這麼優良的傳統文化, ，, 身為卑南...  \n862  [2, ., 把頭目, （, 領袖, ）, 抬上來了, ，, 把頭目, （, 領袖, ）, ...  \n426                               [週五嗎, ？, 我得問問其他人, 。]  \n330  [其中卑南族的建和與知本部落因往南遷徙時與昔日的排灣族已有血緣之故, ，, 木雕雷同的風格別...  \n458                                       [你們有孩子了嗎, ？]  \n757       [從小結伴做農, ，, 學習編織及料理家務, ，, 也接受婦女道德傳統禮儀的訓練, 。]  \n870                              [保障原住民族之平等地位及自主發展, ，]  \n208  [在蓋房子的前一年就要準備木柱及黃藤, ，, 尋找堅固實心不容易腐朽不會白蟻蛀掉的, ，, ...  \n297    [所謂pa, ’, ira, ’, iraw的古謠是卑南族部落在年祭時男子所吟唱的歌謠, 。]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pyu</th>\n      <th>zho</th>\n      <th>pyu_toks</th>\n      <th>zho_toks</th>\n      <th>pyu_words</th>\n      <th>zho_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>264</th>\n      <td>nu uri paveray pakangaway za muketrep wariyan ...</td>\n      <td>在婚期前十天，男家邀集男性親屬一同搬送聘禮至女家。</td>\n      <td>[▁nu, ▁uri, ▁pa, ver, ay, ▁pakanga, way, ▁za, ...</td>\n      <td>[▁在, 婚, 期, 前, 十, 天, ,, 男, 家, 邀, 集, 男性, 親, 屬, 一...</td>\n      <td>[nu, uri, paveray, pakangaway, za, muketrep, w...</td>\n      <td>[在婚期前十天, ，, 男家邀集男性親屬一同搬送聘禮至女家, 。]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>na Pinuyumayan mu, 'azi kazuwan tu pinitrauwan...</td>\n      <td>卑南族人口雖不多，但卻很團結。卑南族有這麼優良的傳統文化，身為卑南族人，要好好珍惜，並擔任起...</td>\n      <td>[▁na, ▁P, inu, yum, ayan, ▁mu, ,, ▁', azi, ▁ka...</td>\n      <td>[▁, 卑, 南, 族, 人口, 雖, 不, 多, ,, 但, 卻, 很, 團, 結, 。,...</td>\n      <td>[na, Pinuyumayan, mu, ,, ', azi, kazuwan, tu, ...</td>\n      <td>[卑南族人口雖不多, ，, 但卻很團結, 。, 卑南族有這麼優良的傳統文化, ，, 身為卑南...</td>\n    </tr>\n    <tr>\n      <th>862</th>\n      <td>2. puitrasaw lra na ayawan, arasaw lra na ayaw...</td>\n      <td>2.把頭目（領袖）抬上來了，把頭目（領袖）抬起來了，虛詞...…</td>\n      <td>[▁2., ▁pu, itr, asaw, ▁l, ra, ▁na, ▁aya, wan, ...</td>\n      <td>[▁2., 把, 頭, 目, (, 領, 袖, ), 抬, 上, 來, 了, ,, 把, 頭...</td>\n      <td>[2, ., puitrasaw, lra, na, ayawan, ,, arasaw, ...</td>\n      <td>[2, ., 把頭目, （, 領袖, ）, 抬上來了, ，, 把頭目, （, 領袖, ）, ...</td>\n    </tr>\n    <tr>\n      <th>426</th>\n      <td>liyusan pukalruwatr wari? kiyumalra ku ziya ka...</td>\n      <td>週五嗎？我得問問其他人。</td>\n      <td>[▁liy, usan, ▁puk, al, ru, wat, r, ▁wari, ?, ▁...</td>\n      <td>[▁, 週, 五, 嗎, ?, 我, 得, 問, 問, 其他人, 。]</td>\n      <td>[liyusan, pukalruwatr, wari, ?, kiyumalra, ku,...</td>\n      <td>[週五嗎, ？, 我得問問其他人, 。]</td>\n    </tr>\n    <tr>\n      <th>330</th>\n      <td>kani i Pinuyumayan na Kasavakan zi na Katratri...</td>\n      <td>其中卑南族的建和與知本部落因往南遷徙時與昔日的排灣族已有血緣之故，木雕雷同的風格別具特色。</td>\n      <td>[▁kani, ▁i, ▁P, inu, yum, ayan, ▁na, ▁Kasa, v,...</td>\n      <td>[▁其中, 卑, 南, 族, 的, 建, 和, 與, 知, 本, 部落, 因, 往, 南, ...</td>\n      <td>[kani, i, Pinuyumayan, na, Kasavakan, zi, na, ...</td>\n      <td>[其中卑南族的建和與知本部落因往南遷徙時與昔日的排灣族已有血緣之故, ，, 木雕雷同的風格別...</td>\n    </tr>\n    <tr>\n      <th>458</th>\n      <td>ulra lra mu alrak?</td>\n      <td>你們有孩子了嗎？</td>\n      <td>[▁ul, ra, ▁l, ra, ▁mu, ▁al, rak, ?]</td>\n      <td>[▁你們, 有, 孩子, 了, 嗎, ?]</td>\n      <td>[ulra, lra, mu, alrak, ?]</td>\n      <td>[你們有孩子了嗎, ？]</td>\n    </tr>\n    <tr>\n      <th>757</th>\n      <td>kinalrakan murairaip mu'uma, menadanadam mele'...</td>\n      <td>從小結伴做農，學習編織及料理家務，也接受婦女道德傳統禮儀的訓練。</td>\n      <td>[▁kin, al, rakan, ▁mura, ira, ip, ▁mu, ', uma,...</td>\n      <td>[▁從, 小, 結, 伴, 做, 農, ,, 學習, 編, 織, 及, 料理, 家, 務, ...</td>\n      <td>[kinalrakan, murairaip, mu, ', uma, ,, menadan...</td>\n      <td>[從小結伴做農, ，, 學習編織及料理家務, ，, 也接受婦女道德傳統禮儀的訓練, 。]</td>\n    </tr>\n    <tr>\n      <th>870</th>\n      <td>tu nana'uwan kana melrivak 'alrayan zantu ipar...</td>\n      <td>保障原住民族之平等地位及自主發展，</td>\n      <td>[▁tu, ▁nana, ', uwan, ▁kana, ▁mel, ri, vak, ▁'...</td>\n      <td>[▁, 保障, 原, 住, 民族, 之, 平等, 地位, 及, 自, 主, 發展, ,]</td>\n      <td>[tu, nana, ', uwan, kana, melrivak, ', alrayan...</td>\n      <td>[保障原住民族之平等地位及自主發展, ，]</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>nu pararahan za ruma' pakangawayan za sa'ami p...</td>\n      <td>在蓋房子的前一年就要準備木柱及黃藤，尋找堅固實心不容易腐朽不會白蟻蛀掉的，三十、五十甚至一百...</td>\n      <td>[▁nu, ▁par, arahan, ▁za, ▁ruma, ', ▁pakanga, w...</td>\n      <td>[▁在, 蓋, 房, 子, 的, 前, 一年, 就要, 準備, 木, 柱, 及, 黃, 藤,...</td>\n      <td>[nu, pararahan, za, ruma, ', pakangawayan, za,...</td>\n      <td>[在蓋房子的前一年就要準備木柱及黃藤, ，, 尋找堅固實心不容易腐朽不會白蟻蛀掉的, ，, ...</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>na pa'ira'iraw mu iniyam na zekalr i Pinuyumay...</td>\n      <td>所謂pa’ira’iraw的古謠是卑南族部落在年祭時男子所吟唱的歌謠。</td>\n      <td>[▁na, ▁pa, ', ira, ', ira, w, ▁mu, ▁ini, yam, ...</td>\n      <td>[▁所, 謂, pa, &lt;unk&gt;, ira, &lt;unk&gt;, ira, w, 的, 古, &lt;...</td>\n      <td>[na, pa, ', ira, ', iraw, mu, iniyam, na, zeka...</td>\n      <td>[所謂pa, ’, ira, ’, iraw的古謠是卑南族部落在年祭時男子所吟唱的歌謠, 。]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23}]}